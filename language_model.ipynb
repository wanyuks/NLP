{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语言模型\n",
    "利用pytorch训练一个语言模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习利用torchtext来创建vocabulary，然后把数据读成batch_size的格式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.vocab import Vectors\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "\n",
    "# USE_CUDA = torch.cuda.is_available()\n",
    "\n",
    "# 为了保证实验结果的一致性，把random_seed固定在一个值\n",
    "random.seed(53113)\n",
    "np.random.seed(53113)\n",
    "torch.manual_seed(53113)\n",
    "# if USE_CUDA:\n",
    "#     torch.manual_seed(53113)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MAX_VOCAB_SIZE = 50000\n",
    "EMBEDDING_SIZE = 100\n",
    "HIDDEN_SIZE = 100\n",
    "NUM_EPOCHS = 2\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用torchtext来读取数据\n",
    "- torchtext的一个重要概念就是Field，他决定了你的数据是如何处理，我们使用TEXT的这个类来处理文本数据；\n",
    "- torchtext提供了LanguageModelingDataset这个类来帮我们处理语言模型数据集；\n",
    "- build_vocab可以根据我们提供的训练数据集来创建最高频词的单词表，max_size来帮助我们限定单词总量；\n",
    "- BPTTIterator可以连续的得到连贯的句子，BPTT的全过程是back propagation through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = torchtext.data.Field(lower=True)\n",
    "train, val, test = torchtext.datasets.LanguageModelingDataset.splits(path='./text8', \n",
    "                                                  train='text8.train.txt', \n",
    "                                                  validation='text8.dev.txt', \n",
    "                                                  test='text8.test.txt',\n",
    "                                                 text_field=TEXT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50002"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.build_vocab(train, max_size=MAX_VOCAB_SIZE)\n",
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单词表有50002而不是5000是因为torchtext给我们增加了两个特殊的token，<unk>表示未知的单词，<pad>表示padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', '<pad>', 'the', 'of', 'and', 'one', 'in', 'a', 'to', 'zero']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词典index to string\n",
    "type(TEXT.vocab.itos) #list\n",
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.defaultdict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词典string to index\n",
    "print(type(TEXT.vocab.stoi)) #collections.defaultdict\n",
    "TEXT.vocab.stoi['july']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = torchtext.data.BPTTIterator.splits((train, val, test),\n",
    "                                                                     batch_size=BATCH_SIZE,\n",
    "#                                                                      device=torch.device('cuda'),\n",
    "                                                                    bptt_len=50,\n",
    "                                                                    repeat=False,\n",
    "                                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 32]\n",
       "\t[.text]:[torch.LongTensor of size 50x32]\n",
       "\t[.target]:[torch.LongTensor of size 50x32]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(train_iter)\n",
    "batch = next(it)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch.text表示的是输入的句子，batch,target表示预测的句子，维度都是50*32  \n",
    "下面看看.text的内容\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4815,   50,    6,  ..., 9116,   33,    7],\n",
       "        [3143, 2748,  495,  ...,  893,  277,  317],\n",
       "        [  13,    8,  850,  ...,  664,  824, 1602],\n",
       "        ...,\n",
       "        [   8,   34,  522,  ..., 5237,    3,   12],\n",
       "        [3628, 1266,  968,  ...,    3,    2,    6],\n",
       "        [   2,   54,   78,  ...,   12,  185, 3027]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将index转化成string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the\n",
      "originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization\n"
     ]
    }
   ],
   "source": [
    "# 第二个维度表示的是batch的大小\n",
    "print(\" \".join(TEXT.vocab.itos[i] for i in batch.text[:,0].data.cpu()))\n",
    "print(\" \".join(TEXT.vocab.itos[i] for i in batch.target[:,0].data.cpu()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到.text的内容和.target的内容仅相差一个位置的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的输入是一串文字，输出也是一串文字，他们之间相差一个位置，因为语言模型的的目标是根据之前的单词预测下一个单词"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义模型\n",
    "- 继承nn.Module\n",
    "- 初始化函数\n",
    "- forward函数\n",
    "- 其余可以根据模型需要定义的相关函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self,input_text, hidden):\n",
    "        # input_text: sqe_len * BATCH_SIZE\n",
    "        emb = self.embed(input_text)\n",
    "        output, hidden = self.lstm(emb, hidden)\n",
    "        '''\n",
    "        out_put: seq_len * batch_size * hidden_size\n",
    "        hiddenL (1 * batch_size * hidden_size, 1 * batch_size * hidden_size)\n",
    "        '''\n",
    "        # output = output.view(-1, output.shape[2])  # (seq_len * batch_size) * hidden_size\n",
    "        out_vocab = self.linear(output.view(-1, output.shape[2]))   # (seq_len * batch_size) * vocab_size\n",
    "        out_vocab = out_vocab.view(out_vocab.shape[0], out_vocab.shape[1], -1)\n",
    "        return out_vocab, hidden\n",
    "    \n",
    "    def init_hidden(self, bsz, requires_grad=True):\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros((1, bsz, self.hidden_size), requires_grad=True),\n",
    "                weight.new_zeros((1, bsz, self.hidden_size), requires_grad=True))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化一个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(vocab_size=len(TEXT.vocab), embed_size=EMBEDDING_SIZE, hidden_size=HIDDEN_SIZE)\n",
    "# if USE_CUDA:\n",
    "#     model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4029,  0.3864,  0.5945,  ..., -1.9139, -0.3455, -0.9382],\n",
       "        [ 0.2939, -0.0949,  0.7116,  ..., -0.2196, -0.2233, -1.8917],\n",
       "        [-0.3359,  1.6099,  1.1068,  ...,  0.2782, -0.6299,  2.3107],\n",
       "        ...,\n",
       "        [ 1.1677,  0.9386, -0.7086,  ..., -0.4453,  0.1337,  2.0498],\n",
       "        [-1.4050, -1.4229, -1.1365,  ...,  0.8331,  0.9180,  0.5792],\n",
       "        [ 1.4029, -0.7460,  1.0759,  ..., -1.0833, -0.9645,  0.5022]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackge_hidden(h):\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackge_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data):\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    total_count = 0.\n",
    "    it = iter(data)\n",
    "    with torch.no_grad():\n",
    "        hidden = model.init_hidden(bsz=BATCH_SIZE, requires_grad=False)\n",
    "        for i, batch in enumerate(it):\n",
    "            data, target = batch.text, batch.target\n",
    "            hidden = repackge_hidden(hidden)\n",
    "            output, hidden = model(data, hidden)\n",
    "            loss = loss_fn(output.view(-1, len(TEXT.vocab)), target.view(-1))\n",
    "            total_loss = loss.item() * np.multiply(*data.size())\n",
    "            total_count = np.multiply(*data.size())\n",
    "    loss = total_loss / total_count\n",
    "    model.train()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 5.804832935333252\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'vla_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-6db180eec18e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mval_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvla_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lm.model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"best mdel saved to lm.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vla_loss' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    it = iter(train_iter)\n",
    "    hidden = model.init_hidden(bsz=BATCH_SIZE)\n",
    "    val_losses = []\n",
    "    for i, batch in enumerate(it):\n",
    "        data, target = batch.text, batch.target\n",
    "        hidden = repackge_hidden(hidden)\n",
    "        output, hidden = model(data, hidden)\n",
    "        loss = loss_fn(output.view(-1, len(TEXT.vocab)), target.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        optimizer.step()\n",
    "        if i % 3 == 0:\n",
    "            print(\"loss\", loss.item())\n",
    "            \n",
    "        # 保存模型\n",
    "        if i % 5 == 0:\n",
    "            # 保存在validation上表现最好的模型\n",
    "            val_loss = evaluate(model, val_iter)\n",
    "            if len(val_losses) == 0 or val_loss < min(val_losses):\n",
    "                val_losses.append(val_loss)\n",
    "                torch.save(model.state_dict(), 'lm.model')\n",
    "                print(\"best mdel saved to lm.model\")\n",
    "            else:\n",
    "                # learning rate decay\n",
    "                scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于计算资源有限，这边只能在cpu上计算，速度特别慢，先把代码保存上传"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
